{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 神经网络的Pytorch API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> torch.nn.Linear(in_features,bias=True,device=None,dtype=None)\n",
    "\n",
    "Applies a linar transformation to the incoming data: $y=xA^T+b$\n",
    "\n",
    "Parameters:\n",
    "- in_features(int), out_features(int): size\n",
    "- bias(bool): True *初始化随机数，可随训练改变*, false *固定*\n",
    "- dtype: 数据类型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "损失函数(loss)：预测值和真值的差异  ${\\rm loss} = \\frac{1}{2} \\left(y-\\hat{y}\\right)^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import pandas as pd # 加载表格\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class iris_dataloader(Dataset):\n",
    "\tdef __init__(self, data_path):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.data_path = data_path\n",
    "\t\tassert os.path.exists(self.data_path)\n",
    "\t\t\n",
    "\t\tdf = pd.read_csv(self.data_path, names=[0,1,2,3,4])\n",
    "\t\td = {\"Iris-setosa\":0, \"Iris-versicolor\":1, \"Iris-virginica\":2}\n",
    "\t\tdf[4] = df[4].map(d)\n",
    "\n",
    "\t\tdata = df.iloc[:, 0:4]\n",
    "\t\tlabel = df.iloc[:, 4]\n",
    "\t\tdata = (data - np.mean(data) / np.std(data)) # 归一化(Z值化)\n",
    "\t\tself._data = torch.from_numpy(np.array(data, dtype='float32'))\n",
    "\t\tself._label = torch.from_numpy(np.array(label, dtype='int64'))\n",
    "\t\tself._data_num = len(label)\n",
    "\n",
    "\t\tself.data = list(self._data)\n",
    "\t\tself.label = list(self._label)\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn self._data_num\n",
    "\n",
    "\tdef __getitem__(self, index): # 获取并返回一个数据样本\n",
    "\t\treturn self.data[index], self.label[index] ## That is Different from Lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化神经网络模型\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "class NN(torch.nn.Module):\n",
    "\tdef __init__(self, in_dim, hid_dim1, hid_dim2, out_dim):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.layer1 = nn.Linear(in_dim, hid_dim1)\n",
    "\t\tself.layer2 = nn.Linear(hid_dim1, hid_dim2)\n",
    "\t\tself.layer3 = nn.Linear(hid_dim2, out_dim)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.layer1(x)\n",
    "\t\tx = x.relu()\n",
    "\t\tx = self.layer2(x)\n",
    "\t\tx = x.relu()\n",
    "\t\tx = self.layer3(x)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 定义计算环境 \n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集的大小: 112\n",
      "验证集的大小: 30\n",
      "测试集的大小: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3643: FutureWarning: The behavior of DataFrame.std with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return std(axis=axis, dtype=dtype, out=out, ddof=ddof, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# 训练集、验证集和测试集\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "custom_dataset = iris_dataloader('./Iris.data.txt')\n",
    "train_size = int(len(custom_dataset) * 0.7)\n",
    "val_size   = int(len(custom_dataset) * 0.2)\n",
    "test_size  = len(custom_dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = \\\n",
    "torch.utils.data.random_split(custom_dataset,[train_size,val_size,test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=False)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=1,  shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=1,  shuffle=False)\n",
    "print(f\"训练集的大小: {len(train_loader)*16}\")\n",
    "print(f\"验证集的大小: {len(val_loader)}\")\n",
    "print(f\"测试集的大小: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个推理函数，来计算并返回准确率\n",
    "import sys\n",
    "import torch.optim as optim\n",
    "def infer(model: torch.nn.Module, dataset, device): \n",
    "\tmodel.eval() # 将模型置于验证状态下\n",
    "\tacc_num = 0\n",
    "\twith torch.no_grad(): # 上下文管理器\n",
    "\t\t# Context-manager that disables gradient calculation.\n",
    "\t\tfor data in dataset:\n",
    "\t\t\tdatas, label = data\n",
    "\t\t\toutputs = model(datas.to(device))\n",
    "\t\t\tpredict_y = torch.max(outputs, dim=1)[1]\n",
    "\t\t\tacc_num += torch.eq(predict_y, label.to(device)).sum().item() # 对每一批数量进行累加\n",
    "\tacc = acc_num / len(dataset)\n",
    "\treturn acc\n",
    "\n",
    "def main(lr = 0.005, epochs = 20):\n",
    "\tmodel = NN(4, 12, 6, 3).to(device) # 最后的分类数\n",
    "\tloss_f = nn.CrossEntropyLoss()\n",
    "\n",
    "\tpg = [p for p in model.parameters() if p.requires_grad] # 列表生成式\n",
    "\toptimizer = optim.Adam(pg, lr=lr) # 可训练的参数\n",
    "\n",
    "\t# 权重的文件存储路径\n",
    "\tsave_path = os.path.join(os.getcwd(), \"result/weights\")\n",
    "\tif os.path.exists(save_path) is False:\n",
    "\t\tos.makedirs(save_path)\n",
    "\n",
    "\t# 开始训练\n",
    "\tfor epoch in range(epochs):\n",
    "\t\tmodel.train()\n",
    "\t\tacc_num = torch.zeros(1).to(device)\n",
    "\t\tsample_num = 0\n",
    "\t\ttrain_bar = tqdm(train_loader, file=sys.stdout, ncols=100)\n",
    "\t\tfor datas in train_bar:\n",
    "\t\t\tdata, label = datas\n",
    "\t\t\tlabel = label.squeeze(-1)\n",
    "\t\t\tsample_num += data.shape[0]\n",
    "\t\t\t\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\toutputs = model(data.to(device))\n",
    "\t\t\tpred_class = torch.max(outputs, dim=1)[1] # torch.max 返回的是元组，[0]为大小 [1]为索引\n",
    "\t\t\tacc_num = torch.eq(pred_class, label.to(device)).sum()\n",
    "\t\t\t\n",
    "\t\t\tloss = loss_f(outputs, label.to(device))\n",
    "\t\t\tloss.backward() # 梯度求导\n",
    "\t\t\toptimizer.step()\n",
    "\n",
    "\t\t\ttrain_acc = acc_num / sample_num\n",
    "\t\t\ttrain_bar.desc = f'Train epoch[{epoch+1}/{epochs}] \\\n",
    "\t\t\t\tACC:{train_acc:.3f} Loss:{loss:.3f}'\n",
    "\t\t\n",
    "\t\t# 在每一轮训练后进行验证\n",
    "\t\tval_acc = infer(model, val_loader, device)\n",
    "\t\tprint(f'Train epoch[{epoch+1}/{epochs}] \\\n",
    "\t\t\tTrain ACC:{train_acc:.3f} Value ACC:{val_acc:.3f}')\n",
    "\t\ttorch.save(model.state_dict(), os.path.join(save_path, \"nn.pth\"))\n",
    "\n",
    "\t\t# 每次数据集迭代后，要对初始化的指标清零\n",
    "\t\ttrain_acc = 0.0\n",
    "\t\tval_acc   = 0.0\n",
    "\tprint('Finish Training')\n",
    "\n",
    "\ttest_acc = infer(model, test_loader, device)\n",
    "\tprint(f'Test ACC: {test_acc}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tmain()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
